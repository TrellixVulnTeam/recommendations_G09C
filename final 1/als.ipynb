{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чередование наименьших квадратов на примере MovieLens (PySpark)\n",
    "\n",
    "Факторизация матрицы с помощью [ALS](https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/recommendation.html#ALS) (метод наименьших квадратов) – алгоритм коллаборативной фильтрации.\n",
    "\n",
    "В данном ноутбуке приведен пример использования алгоритма ALS для предсказания оценки фильма. Обычно используется для больших датасетов. Для примера воспользуемся небольшим набором данных, чтобы улучишть производительность\n",
    "\n",
    "**P.S.**: Для запуска примера необходимо окружение PySpark. [Инструкция по установке](https://github.com/Microsoft/Recommenders/blob/master/SETUP.md#dependencies-setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "System version: 3.8.6 (v3.8.6:db455296be, Sep 23 2020, 13:31:39) \n[Clang 6.0 (clang-600.0.57)]\nSpark version: 3.0.1\n"
     ]
    }
   ],
   "source": [
    "# установим корневой путь и импортируем необходимые бибилиотеки и датасет\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType\n",
    "\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.common.notebook_utils import is_jupyter\n",
    "from reco_utils.dataset.spark_splitters import spark_random_split\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from reco_utils.common.spark_utils import start_or_get_spark\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# выставим стандартные параметры:\n",
    "\n",
    "# топ k элементов для рекомендации\n",
    "TOP_K = 10\n",
    "\n",
    "# размер датасета\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настроим контекст для Spark\n",
    "\n",
    "Настройки ниже хорошо подходят для работы на локальной машине, их стоит изменить при запуске эксперимента на кластере. Выберем один большой исполнитель с большим количеством потоков и укажем объем памяти "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим MovieLens датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:09<00:00, 517KB/s]  \n",
      "+------+-------+------+---------+\n",
      "|UserId|MovieId|Rating|Timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|   3.0|881250949|\n",
      "|   186|    302|   3.0|891717742|\n",
      "|    22|    377|   1.0|878887116|\n",
      "|   244|     51|   2.0|880606923|\n",
      "|   166|    346|   1.0|886397596|\n",
      "|   298|    474|   4.0|884182806|\n",
      "|   115|    265|   2.0|881171488|\n",
      "|   253|    465|   5.0|891628467|\n",
      "|   305|    451|   3.0|886324817|\n",
      "|     6|     86|   3.0|883603013|\n",
      "|    62|    257|   2.0|879372434|\n",
      "|   286|   1014|   5.0|879781125|\n",
      "|   200|    222|   5.0|876042340|\n",
      "|   210|     40|   3.0|891035994|\n",
      "|   224|     29|   3.0|888104457|\n",
      "|   303|    785|   3.0|879485318|\n",
      "|   122|    387|   5.0|879270459|\n",
      "|   194|    274|   2.0|879539794|\n",
      "|   291|   1042|   4.0|874834944|\n",
      "|   234|   1184|   2.0|892079237|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(\n",
    "    (\n",
    "        StructField(\"UserId\", IntegerType()),\n",
    "        StructField(\"MovieId\", IntegerType()),\n",
    "        StructField(\"Rating\", FloatType()),\n",
    "        StructField(\"Timestamp\", LongType()),\n",
    "    )\n",
    ")\n",
    "\n",
    "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим датасет на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N train 74963\nN test 25037\n"
     ]
    }
   ],
   "source": [
    "train, test = spark_random_split(data, ratio=0.75, seed=2415)\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Натренируем ALS модель на train датасете. Получим TOP_K рекоммендаций для test датасета\n",
    "\n",
    "Для предсказания рейтингов будем использовать оценки юзеров из train датасета. Гиперпараметры модели возьмем [отсюда](http://mymedialite.net/examples/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"userCol\": \"UserId\",\n",
    "    \"itemCol\": \"MovieId\",\n",
    "    \"ratingCol\": \"Rating\",\n",
    "}\n",
    "\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.7273268020003343 секунд заняло обучение модели\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train)\n",
    "\n",
    "print(\"{} секунд заняло обучение модели\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. нет смысла работать с уже оцененными юзером фильмы, необходимо их удалить из списка\n",
    "\n",
    "Поэтому сначала построим список всех фильмов для всех пользователей, а затем удалим оцененные фильмы конкретным пользователем, которые уже есть в train датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19.570216943000105 секунд заняло предсказание\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    # объединим таблицы фильмов и пользователей\n",
    "    users = train.select('UserId').distinct()\n",
    "    items = train.select('MovieId').distinct()\n",
    "    user_item = users.crossJoin(items)\n",
    "\n",
    "    # сформируем список\n",
    "    dfs_pred = model.transform(user_item)\n",
    "\n",
    "    # удалим просмотренные\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (dfs_pred['UserId'] == train['UserId']) & (dfs_pred['MovieId'] == train['MovieId']),\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "        .select('pred.' + 'UserId', 'pred.' + 'MovieId', 'pred.' + \"prediction\")\n",
    "\n",
    "    # посчитаем затраченое время\n",
    "    top_all.cache().count()\n",
    "\n",
    "print(\"{} секунд заняло предсказание\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-------+----------+\n|UserId|MovieId|prediction|\n+------+-------+----------+\n|     1|    587|  3.479028|\n|     1|    869|  2.895633|\n|     1|   1208| 3.0098994|\n|     1|   1357| 1.6365523|\n|     2|     80| 2.8625576|\n|     2|    472| 3.0787597|\n|     2|    582| 3.7146451|\n|     2|    838| 1.7649673|\n|     2|    975| 3.0761478|\n|     2|   1260| 2.2481644|\n|     2|   1325| 2.0101647|\n|     2|   1381| 3.6680305|\n|     2|   1530| 2.7652826|\n|     3|     22|  3.518471|\n|     3|     57| 3.4261537|\n|     3|     89| 3.4682543|\n|     3|    367|  2.986559|\n|     3|   1091| 2.3534873|\n|     3|   1167|   3.13494|\n|     3|   1499|  3.535588|\n+------+-------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "top_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим работу ALS модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=\"UserId\", col_item=\"MovieId\", \n",
    "                                    col_rating=\"Rating\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model:\tALS\nTop K:\t10\nMAP:\t0.003964\nNDCG:\t0.038735\nPrecision@K:\t0.042418\nRecall@K:\t0.014965\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Top K:\\t%d\" % rank_eval.k,\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим предсказание оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-------+------+---------+----------+\n|UserId|MovieId|Rating|Timestamp|prediction|\n+------+-------+------+---------+----------+\n|   332|    148|   5.0|887938486| 3.5596893|\n|   236|    148|   4.0|890117028| 2.4714663|\n|   178|    148|   4.0|882824325| 3.6450977|\n|   328|    148|   3.0|885048638|  3.253691|\n|   919|    148|   3.0|875289417| 2.4988792|\n|    54|    148|   3.0|880937490| 3.1066952|\n|   120|    148|   3.0|889490499| 3.0998797|\n|    92|    148|   2.0|877383934| 2.7356203|\n|   486|    148|   2.0|879874903| 2.0614953|\n|   552|    148|   3.0|879222452| 3.1767642|\n|   834|    148|   4.0|890862563| 3.6788952|\n|    59|    148|   3.0|888203175|  2.887632|\n|   757|    148|   4.0|888444948| 3.0533493|\n|   434|    148|   3.0|886724797| 3.1537614|\n|   391|    148|   3.0|877400062| 2.1381872|\n|   438|    148|   5.0|879868443| 3.7995524|\n|   532|    148|   5.0|888817717|  3.897446|\n|   821|    148|   3.0|874792650| 3.2801647|\n|   793|    148|   4.0|875104498| 2.9910336|\n|   938|    148|   3.0|891356500|  4.627634|\n+------+-------+------+---------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test)\n",
    "prediction.cache().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model:\tALS rating prediction\nRMSE:\t0.970564\nMAE:\t0.753342\nExplained variance:\t0.256275\nR squared:\t0.252496\n"
     ]
    }
   ],
   "source": [
    "rating_eval = SparkRatingEvaluation(test, prediction, col_user=\"UserId\", col_item=\"MovieId\", \n",
    "                                    col_rating=\"Rating\", col_prediction=\"prediction\")\n",
    "\n",
    "print(\"Model:\\tALS rating prediction\",\n",
    "      \"RMSE:\\t%f\" % rating_eval.rmse(),\n",
    "      \"MAE:\\t%f\" % rating_eval.mae(),\n",
    "      \"Explained variance:\\t%f\" % rating_eval.exp_var(),\n",
    "      \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# освободим ресурсы\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}