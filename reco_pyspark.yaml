# 
# To create the conda environment:
# $ conda env create -f reco_pyspark.yaml
# 
# To update the conda environment:
# $ conda env update -f reco_pyspark.yaml
# 
# To register the conda environment in Jupyter:
# $ conda activate reco_pyspark
# $ python -m ipykernel install --user --name reco_pyspark --display-name "Python (reco_pyspark)"
# 
name: reco_pyspark
channels:
- defaults
- conda-forge
- pytorch
- fastai
dependencies:
- cornac>=1.1.2
- ipykernel>=4.6.1
- lightfm>=1.15
- dask>=0.17.1
- pip>=19.2
- fastparquet>=0.1.6
- seaborn>=0.8.1
- pyarrow>=0.8.0
- pytest>=3.6.4
- numpy>=1.13.3
- pandas>=0.23.4,<1.0.0
- mock==2.0.0
- tqdm>=4.31.1
- lightgbm==2.2.1
- pyspark==2.4.5
- python==3.6.11
- swig==3.0.12
- scikit-surprise>=1.0.6
- matplotlib>=2.2.2
- pytorch-cpu>=1.0.0
- scipy>=1.0.0
- bottleneck==1.2.1
- jupyter>=1.0.0
- papermill==0.19.1
- scikit-learn>=0.19.1
- nltk>=3.4
- pip:
  - xlearn==0.40a1
  - azure-cli-core==2.0.75
  - transformers==2.5.0
  - databricks-cli==0.8.6
  - pymanopt==0.2.5
  - dataclasses>=0.6
  - nni==1.5
  - hyperopt==0.1.1
  - azure-mgmt-cosmosdb==0.8.0
  - category_encoders>=1.3.0
  - pydocumentdb>=2.3.3
  - azure-storage-blob<=2.1.0
  - black>=18.6b4
  - azureml-sdk[notebooks,tensorboard]==1.0.69
  - locustio==0.11.0
  - nbconvert==5.5.0
  - memory-profiler>=0.54.0
  - idna==2.7
  - tensorflow==1.15.2
